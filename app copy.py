import streamlit as st
import cv2
import numpy as np
from PIL import Image
from insightface.app import FaceAnalysis
import os
from pathlib import Path
import torch
import random

# Initialize face analyzer with caching
@st.cache_resource
def init_face_analyzer():
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ MPS
    if torch.backends.mps.is_available():
        st.sidebar.success("Using M2 GPU (Metal)")
        # à¹ƒà¸Šà¹‰ MPS backend
        analyzer = FaceAnalysis(
            name="buffalo_l",
            providers=['MPSExecutionProvider'],
            allowed_modules=['detection', 'recognition']  # à¹€à¸žà¸´à¹ˆà¸¡à¹‚à¸¡à¸”à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ GPU
        )
        analyzer.prepare(ctx_id=0)  # à¹ƒà¸Šà¹‰ GPU
    else:
        st.sidebar.info("Using CPU")
        # Fallback to CPU
        analyzer = FaceAnalysis(
            name="buffalo_l",
            providers=['CPUExecutionProvider']
        )
        analyzer.prepare(ctx_id=-1)
    
    return analyzer

# Cache database loading
@st.cache_data
def load_database_images(database_dir, _face_analyzer, max_samples=200):
    """à¹‚à¸«à¸¥à¸”à¸£à¸¹à¸›à¹à¸¥à¸° random sampling à¹ƒà¸«à¹‰à¹€à¸«à¸¥à¸·à¸­à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ max_samples"""
    database = []
    
    # à¹ƒà¸Šà¹‰ progress bar
    progress_text = st.sidebar.empty()
    progress_bar = st.sidebar.progress(0)
    
    # à¸£à¸§à¸šà¸£à¸§à¸¡à¸£à¸¹à¸›à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
    all_images = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        all_images.extend(list(Path(database_dir).glob(ext)))
    
    # à¸ªà¸¸à¹ˆà¸¡à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›
    if len(all_images) > max_samples:
        st.sidebar.warning(f"Sampling {max_samples} images from {len(all_images)} total images")
        selected_images = random.sample(all_images, max_samples)
    else:
        selected_images = all_images
    
    # à¹ƒà¸Šà¹‰ batch processing
    batch_size = 10
    total_batches = len(selected_images) // batch_size + 1
    
    for batch_idx in range(total_batches):
        start_idx = batch_idx * batch_size
        end_idx = min((batch_idx + 1) * batch_size, len(selected_images))
        batch_images = selected_images[start_idx:end_idx]
        
        # à¸­à¸±à¸žà¹€à¸”à¸— progress
        progress = (batch_idx + 1) / total_batches
        progress_text.text(f"Loading images: {int(progress * 100)}%")
        progress_bar.progress(progress)
        
        # Process batch
        for img_path in batch_images:
            try:
                img = cv2.imread(str(img_path))
                if img is not None:
                    # Resize à¹ƒà¸«à¹‰à¹€à¸¥à¹‡à¸à¸¥à¸‡à¹€à¸žà¸·à¹ˆà¸­à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™
                    img = preprocess_image(img, max_size=320)  # à¸¥à¸”à¸‚à¸™à¸²à¸”à¸¥à¸‡
                    faces = _face_analyzer.get(img)
                    if faces:
                        database.append({
                            "path": str(img_path),
                            "embeddings": [face.normed_embedding for face in faces]
                        })
            except Exception as e:
                st.sidebar.error(f"Error loading {img_path}: {str(e)}")
                continue
    
    # Clear progress
    progress_text.empty()
    progress_bar.empty()
    
    return database

# Optimize image size
def preprocess_image(image, max_size=640):
    h, w = image.shape[:2]
    if max(h, w) > max_size:
        scale = max_size / max(h, w)
        new_size = (int(w * scale), int(h * scale))
        image = cv2.resize(image, new_size)
    return image

# Vectorized matching
@st.cache_data
def find_matches_vectorized(query_embedding, database, threshold):
    if not database or query_embedding is None:
        return []
    
    # Combine all embeddings into a single matrix
    all_embeddings = []
    all_paths = []
    for db in database:
        if db.get("embeddings"):  # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µ embeddings
            all_embeddings.extend(db["embeddings"])
            all_paths.extend([db["path"]] * len(db["embeddings"]))
    
    if not all_embeddings:
        return []
        
    try:
        # Calculate similarities in one go
        all_embeddings = np.vstack(all_embeddings)
        similarities = np.dot(all_embeddings, query_embedding)
        
        # Find matches above threshold
        mask = similarities > threshold
        matches = [{
            "path": path,
            "similarity": float(sim)
        } for path, sim in zip(np.array(all_paths)[mask], similarities[mask])]
        
        return sorted(matches, key=lambda x: x["similarity"], reverse=True)
    except Exception as e:
        st.error(f"Error in matching: {str(e)}")
        return []

# Efficient result display
def display_results(matches, cols=3):
    if not matches:
        return
    
    # à¸à¸£à¸­à¸‡à¹€à¸‰à¸žà¸²à¸° matches à¸—à¸µà¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¸„à¸¥à¹‰à¸²à¸¢à¹€à¸à¸´à¸™ 25%
    filtered_matches = [m for m in matches if m.get('similarity', 0) * 100 >= 25]
    
    if not filtered_matches:
        st.write("No matches above 25% similarity")
        return
    
    # à¹à¸ªà¸”à¸‡à¸ˆà¸³à¸™à¸§à¸™à¸£à¸¹à¸›à¸—à¸µà¹ˆà¹€à¸ˆà¸­
    st.write(f"Found {len(filtered_matches)} matches above 25% similarity")
    
    # à¹à¸šà¹ˆà¸‡à¸à¸²à¸£à¹à¸ªà¸”à¸‡à¸œà¸¥à¹€à¸›à¹‡à¸™à¹à¸–à¸§ à¹à¸–à¸§à¸¥à¸° 3 à¸£à¸¹à¸›
    for i in range(0, len(filtered_matches), cols):
        columns = st.columns(cols)
        for j, match in enumerate(filtered_matches[i:i+cols]):
            with columns[j]:
                similarity_percent = f"{match['similarity']*100:.1f}%"
                match_img = cv2.imread(match["path"])
                if match_img is not None:
                    match_img = cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB)
                    st.image(match_img, caption=f"Similarity: {similarity_percent}")

def main():
    st.title("Zero-shot Face Recognition ðŸ‘¤")
    
    # Initialize components
    status = st.empty()
    progress = st.progress(0)
    face_analyzer = init_face_analyzer()
    
    # Load database
    status.text("Loading database...")
    database_dir = "database"
    Path(database_dir).mkdir(exist_ok=True)
    database = load_database_images(database_dir, face_analyzer)
    
    # UI Controls
    with st.sidebar:
        st.write(f"Database images: {len(database)}")
        similarity_threshold = st.slider(
            "Similarity Threshold", 
            min_value=0.0, 
            max_value=1.0, 
            value=0.25
        )

    status.text("Ready for image upload")
    progress.progress(100)
    
    uploaded_file = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        try:
            status.text("Processing image...")
            progress.progress(30)
            
            # Read and preprocess image
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            image = preprocess_image(image)
            
            # Detect faces
            status.text("Detecting faces...")
            faces = face_analyzer.get(image)
            progress.progress(60)
            
            if len(faces) > 0:
                status.text(f"Found {len(faces)} faces")
                
                # Create columns for results
                result_cols = st.columns(min(len(faces), 3))
                
                for i, (face, col) in enumerate(zip(faces, result_cols)):
                    with col:
                        # Show face info
                        gender = "Male" if face.sex == 1 else "Female"
                        age = int(face.age) if face.age is not None else 0
                        st.write(f"Face #{i+1}: {gender}, {age} years")
                        
                        # Find and display matches
                        matches = find_matches_vectorized(
                            face.normed_embedding, 
                            database, 
                            similarity_threshold
                        )
                        display_results(matches)
                
                status.text("Processing complete!")
                progress.progress(100)
                
            else:
                status.text("No faces detected")
                progress.progress(100)
                
        except Exception as e:
            st.error(f"Error: {str(e)}")
            progress.progress(100)

if __name__ == "__main__":
    st.set_page_config(
        page_title="Face Recognition",
        page_icon="ðŸ‘¤",
        layout="wide"
    )
    main() 